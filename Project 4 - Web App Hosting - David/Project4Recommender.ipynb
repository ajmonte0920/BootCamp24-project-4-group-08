{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "252FgwUhJOfj",
        "outputId": "4f1f2aaf-6986-4e64-ffee-ed81169c5d10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0 (from gradio)\n",
            "  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio)\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.7)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.6.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.3)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.31.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi<1.0->gradio)\n",
            "  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading ruff-0.6.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.31.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.38.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, orjson, h11, ffmpy, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.0 ffmpy-0.4.0 gradio-4.44.1 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 orjson-3.10.7 pydub-0.25.1 python-multipart-0.0.12 ruff-0.6.8 semantic-version-2.10.0 starlette-0.38.6 tomlkit-0.12.0 uvicorn-0.31.0 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Collecting Movie Posters\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import time\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "# ==========================\n",
        "# 1. Load and Preprocess Data\n",
        "# ==========================\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/16k_Movies.csv')\n",
        "\n",
        "# Handle missing values\n",
        "df = df.dropna(subset=['Title', 'Description'])\n",
        "df['Rating'] = df['Rating'].fillna(df['Rating'].mean())\n",
        "df['Genres'] = df['Genres'].fillna('')\n",
        "\n",
        "# Combine 'Description' and 'Genres'\n",
        "df['Combined_Features'] = df['Description'] + ' ' + df['Genres']"
      ],
      "metadata": {
        "id": "9tKaREVkJcdP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DO NOT RE-RUN CELL #3!!!** *I've already collected all the movie Posters. This took approximatly 1:30 minutes to run and complete:*"
      ],
      "metadata": {
        "id": "XIPSgbk1Lx8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# 2. Obtain Poster URLs\n",
        "# ==========================\n",
        "\n",
        "# Your TMDb API key, Create a TMBD account and Enter the API Key here\n",
        "TMDB_API_KEY = ''\n",
        "\n",
        "# Base URL for TMDb images\n",
        "TMDB_IMAGE_BASE_URL = 'https://image.tmdb.org/t/p/w500'\n",
        "\n",
        "def get_poster_url(title, year=None):\n",
        "    search_url = f\"https://api.themoviedb.org/3/search/movie\"\n",
        "    params = {\n",
        "        'api_key': TMDB_API_KEY,\n",
        "        'query': title,\n",
        "        'year': year,\n",
        "        'language': 'en-US',\n",
        "        'page': 1,\n",
        "        'include_adult': False\n",
        "    }\n",
        "    response = requests.get(search_url, params=params)\n",
        "    if response.status_code != 200:\n",
        "        return None\n",
        "    data = response.json()\n",
        "\n",
        "    if data['results']:\n",
        "        poster_path = data['results'][0]['poster_path']\n",
        "        if poster_path:\n",
        "            return TMDB_IMAGE_BASE_URL + poster_path\n",
        "    return None\n",
        "\n",
        "# Load existing poster URLs if available\n",
        "try:\n",
        "    df_posters = pd.read_pickle('df_with_posters.pkl')\n",
        "    print(\"Loaded existing poster URLs.\")\n",
        "except FileNotFoundError:\n",
        "    df_posters = df.copy()\n",
        "    df_posters['Poster_URL'] = None\n",
        "    print(\"Initialized Poster_URL column.\")\n",
        "\n",
        "# Function to extract year from 'Release Date'\n",
        "def extract_year(release_date):\n",
        "    if pd.isnull(release_date):\n",
        "        return None\n",
        "    try:\n",
        "        return int(pd.to_datetime(release_date).year)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Iterate over the DataFrame to fetch poster URLs\n",
        "for idx, row in df_posters.iterrows():\n",
        "    if pd.isnull(row['Poster_URL']):\n",
        "        title = row['Title']\n",
        "        year = extract_year(row['Release Date'])\n",
        "        poster_url = get_poster_url(title, year)\n",
        "        df_posters.at[idx, 'Poster_URL'] = poster_url\n",
        "        print(f\"Fetched poster for: {title}\")\n",
        "        # Save progress every 1000 iterations\n",
        "        if idx % 1000 == 0:\n",
        "            df_posters.to_pickle('df_with_posters.pkl')\n",
        "            print(\"Saved progress.\")\n",
        "        # Respect TMDb rate limits (40 requests per 10 seconds)\n",
        "        time.sleep(0.25)\n",
        "    else:\n",
        "        print(f\"Poster already exists for: {row['Title']}\")\n",
        "\n",
        "# Save the final DataFrame with poster URLs\n",
        "df_posters.to_pickle('df_with_posters.pkl')\n",
        "print(\"Completed fetching all poster URLs.\")"
      ],
      "metadata": {
        "id": "oRjC1E0NKDvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the DataFrame with poster URLs\n",
        "df = pd.read_pickle('df_with_posters.pkl')\n",
        "\n",
        "# ==========================\n",
        "# 3. Compute Cosine Similarity\n",
        "# ==========================\n",
        "\n",
        "# Initialize the TF-IDF Vectorizer\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "# Replace NaN with empty string in 'Combined_Features'\n",
        "df['Combined_Features'] = df['Combined_Features'].fillna('')\n",
        "\n",
        "# Compute TF-IDF matrix\n",
        "tfidf_matrix = tfidf.fit_transform(df['Combined_Features'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "print(\"Cosine similarity matrix computed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMBJjOwaKJ79",
        "outputId": "5af6dec3-f6f8-4f17-cad9-cbc1e243e017"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity matrix computed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# 4. Recommendation Function\n",
        "# ==========================\n",
        "\n",
        "# Define a default placeholder image URL\n",
        "DEFAULT_POSTER_URL = 'https://via.placeholder.com/200x300?text=No+Image'\n",
        "\n",
        "\n",
        "# Create a reverse mapping from title to index\n",
        "indices = pd.Series(df.index, index=df['Title'].str.lower()).drop_duplicates()\n",
        "\n",
        "def get_recommendations(title, cosine_sim=cosine_sim):\n",
        "    \"\"\"\n",
        "    Given a movie title, return the top 10 similar movies.\n",
        "    \"\"\"\n",
        "    title = title.lower().strip()\n",
        "    if title not in indices:\n",
        "        return \"Movie title not found. Please check the spelling and try again.\"\n",
        "\n",
        "    idx = indices[title]\n",
        "\n",
        "    # Get the pairwise similarity scores\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "\n",
        "    # Sort based on similarity scores\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Get the scores of the top 11 movies (including itself)\n",
        "    sim_scores = sim_scores[1:11]\n",
        "\n",
        "    # Get the movie indices\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "\n",
        "    # Retrieve the movie titles and poster URLs\n",
        "    recommended_titles = df['Title'].iloc[movie_indices].tolist()\n",
        "    recommended_posters = df['Poster_URL'].iloc[movie_indices].tolist()\n",
        "    recommended_genres = df['Genres'].iloc[movie_indices].tolist()\n",
        "    recommended_ratings = df['Rating'].iloc[movie_indices].tolist()\n",
        "\n",
        "    # Combine all information into a list of dictionaries\n",
        "    recommendations = []\n",
        "    for title, poster, genre, rating in zip(recommended_titles, recommended_posters, recommended_genres, recommended_ratings):\n",
        "        recommendations.append({\n",
        "            'Title': title,\n",
        "            'Poster_URL': poster if pd.notnull(poster) else DEFAULT_POSTER_URL,\n",
        "            'Genres': genre,\n",
        "            'Rating': rating\n",
        "        })\n",
        "\n",
        "    return recommendations\n"
      ],
      "metadata": {
        "id": "PgVy3a6zKOJz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing\n",
        "get_recommendations('The Dark Knight Rises')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySvV3bLlKSTE",
        "outputId": "0c2fefb8-13af-4d28-bc08-cf442c1c175d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Title': 'Batman Begins',\n",
              "  'Poster_URL': 'https://image.tmdb.org/t/p/w500/4MpN4kIEqUjW8OPtOQJXlTdHiJV.jpg',\n",
              "  'Genres': 'Action,Crime,Drama',\n",
              "  'Rating': 8.3},\n",
              " {'Title': 'The Dark Knight',\n",
              "  'Poster_URL': 'https://image.tmdb.org/t/p/w500/qJ2tW6WMUDux911r6m7haRef0WH.jpg',\n",
              "  'Genres': 'Action,Crime,Drama,Thriller',\n",
              "  'Rating': 8.9},\n",
              " {'Title': 'Batman Returns',\n",
              "  'Poster_URL': 'https://image.tmdb.org/t/p/w500/jKBjeXM7iBBV9UkUcOXx3m7FSHY.jpg',\n",
              "  'Genres': 'Action,Crime,Fantasy',\n",
              "  'Rating': 8.1},\n",
              " {'Title': 'Batman v Superman: Dawn of Justice',\n",
              "  'Poster_URL': 'https://image.tmdb.org/t/p/w500/5UsK3grJvtQrtzEgqNlDljJW96w.jpg',\n",
              "  'Genres': 'Action,Adventure,Sci-Fi',\n",
              "  'Rating': 7.0},\n",
              " {'Title': 'Batman Forever',\n",
              "  'Poster_URL': 'https://image.tmdb.org/t/p/w500/mzzNBVwTiiY94xAXDMWJpNPW2US.jpg',\n",
              "  'Genres': 'Action,Adventure',\n",
              "  'Rating': 6.8},\n",
              " {'Title': 'The LEGO Batman Movie',\n",
              "  'Poster_URL': 'https://image.tmdb.org/t/p/w500/snGwr2gag4Fcgx2OGmH9otl6ofW.jpg',\n",
              "  'Genres': 'Animation,Action,Adventure,Comedy,Family,Fantasy,Sci-Fi',\n",
              "  'Rating': 7.6},\n",
              " {'Title': 'Batman',\n",
              "  'Poster_URL': 'https://image.tmdb.org/t/p/w500/oYWUsIVoMl2H6Xl3FTBi9R9Y4OS.jpg',\n",
              "  'Genres': 'Action,Adventure',\n",
              "  'Rating': 8.1},\n",
              " {'Title': 'The Batman',\n",
              "  'Poster_URL': 'https://image.tmdb.org/t/p/w500/74xTEgt7R36Fpooo50r9T25onhq.jpg',\n",
              "  'Genres': 'Action,Crime,Drama,Mystery,Thriller',\n",
              "  'Rating': 7.5},\n",
              " {'Title': 'Justice League',\n",
              "  'Poster_URL': 'https://image.tmdb.org/t/p/w500/eifGNCSDuxJeS1loAXil5bIGgvC.jpg',\n",
              "  'Genres': 'Action,Adventure,Fantasy,Sci-Fi',\n",
              "  'Rating': 6.0},\n",
              " {'Title': '16 Blocks',\n",
              "  'Poster_URL': 'https://image.tmdb.org/t/p/w500/cBLqMVfTZpuKmMQKDLKusb93dbR.jpg',\n",
              "  'Genres': 'Action,Drama,Thriller',\n",
              "  'Rating': 8.1}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================\n",
        "# 5. Enhanced Gradio Interface\n",
        "# ==========================\n",
        "def format_recommendations(recommendations):\n",
        "    if isinstance(recommendations, str):\n",
        "        # If an error message is returned\n",
        "        return f\"<p style='color: red; text-align: center;'>{recommendations}</p>\"\n",
        "    else:\n",
        "        # Create HTML content with movie titles and posters\n",
        "        html_content = \"<div style='display: flex; flex-wrap: wrap; gap: 20px; justify-content: center;'>\"\n",
        "        for movie in recommendations:\n",
        "            title = movie['Title']\n",
        "            poster = movie['Poster_URL']\n",
        "            genres = movie['Genres']\n",
        "            rating = movie['Rating']\n",
        "            movie_card = f\"\"\"\n",
        "            <div class='movie-card' style='width: 200px; text-align: center;'>\n",
        "                <img src='{poster}' alt='{title}' style='width: 100%; height: auto; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.2);'>\n",
        "                <h3 style='font-size: 1.1em; margin-top: 10px;'>{title}</h3>\n",
        "                <p style='color: #555;'>{genres}</p>\n",
        "                <p style='color: #777;'>Rating: {rating}</p>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "            html_content += movie_card\n",
        "        html_content += \"</div>\"\n",
        "        return html_content\n",
        "\n",
        "#Testing\n",
        "#format_recommendations(get_recommendations('The Dark Knight Rises'))"
      ],
      "metadata": {
        "id": "PvnDcAh5KVX0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get list of all unique movie titles for autocomplete\n",
        "all_titles = df['Title'].unique().tolist()\n",
        "all_titles[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0_YJafeKYJV",
        "outputId": "f34dd284-fe47-4e34-a79e-dcc2fcb15af3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dekalog (1988)',\n",
              " 'Three Colors: Red',\n",
              " 'The Conformist',\n",
              " 'Tokyo Story',\n",
              " 'The Leopard (re-release)',\n",
              " 'The Godfather',\n",
              " 'Boyhood',\n",
              " 'Lawrence of Arabia (re-release)',\n",
              " 'Fanny and Alexander (re-release)',\n",
              " 'Playtime']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "# Define the Gradio Blocks interface\n",
        "with gr.Blocks(css=\"\"\"\n",
        "    body {\n",
        "        background-color: #f0f2f5;\n",
        "        font-family: Arial, sans-serif;\n",
        "    }\n",
        "    .header {\n",
        "        text-align: center;\n",
        "        padding: 20px;\n",
        "    }\n",
        "    .recommendation-section {\n",
        "        margin-top: 20px;\n",
        "    }\n",
        "    .movie-card {\n",
        "        transition: transform 0.2s;\n",
        "    }\n",
        "    .movie-card:hover {\n",
        "        transform: scale(1.05);\n",
        "    }\n",
        "    .gradio-container {\n",
        "        max-width: 1200px;\n",
        "        margin: auto;\n",
        "    }\n",
        "\"\"\") as demo:\n",
        "    # Header\n",
        "    gr.Markdown(\"<h1 style='text-align: center; color: #333;'>ğŸ¬ Movie Recommender System</h1>\")\n",
        "    gr.Markdown(\"<p style='text-align: center; color: #555;'>Enter a movie title to receive top 10 recommendations based on similarity.</p>\")\n",
        "\n",
        "    # Input Section\n",
        "    with gr.Row():\n",
        "        input_movie = gr.Textbox(\n",
        "            lines=1,\n",
        "            placeholder=\"Enter a movie title...\",\n",
        "            label=\"Movie Title\",\n",
        "            interactive=True\n",
        "        )\n",
        "        recommend_btn = gr.Button(\"Get Recommendations\", variant=\"primary\")\n",
        "\n",
        "    # Output Section\n",
        "    with gr.Row():\n",
        "        recommendations_output = gr.HTML(label=\"Recommended Movies\")\n",
        "\n",
        "    # Event Handling\n",
        "    recommend_btn.click(\n",
        "        fn=lambda title: format_recommendations(get_recommendations(title)),\n",
        "        inputs=input_movie,\n",
        "        outputs=recommendations_output\n",
        "    )\n",
        "\n",
        "    # Footer\n",
        "    gr.Markdown(\"<p style='text-align: center; margin-top: 40px; color: #888;'>Â© 2024 MovieRecommender Inc.</p>\")\n",
        "\n",
        "# Launch the app\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "ffEWq9ZIKbHu",
        "outputId": "77497275-75fb-46f3-81f1-e18fac3253c0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://17c798b93382c15745.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://17c798b93382c15745.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}